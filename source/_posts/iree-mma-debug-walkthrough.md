---
title: IREE MMA åŸ·è¡Œæµç¨‹å®Œæ•´åˆ†æ
date: 2025-11-07 09:50:00
tags:
categories:
thumbnail: /img/iree-mma-debug-walkthrough_files/encrypted-tbn0_gstatic_com_image.png
---
> é€™ä»½æ–‡ä»¶ä»¥ samples/jerry_test/jerry_mma_debug.log ç‚ºåŸºç¤ï¼Œå®Œæ•´è§£æ IREE ç·¨è­¯å™¨åœ¨ GPU å¾Œç«¯ï¼ˆç‰¹åˆ¥æ˜¯ AMD RDNA3 æ¶æ§‹ï¼‰æ¨å° MMAï¼ˆMatrix Multiply-Accumulateï¼‰Schedule çš„æ•´å€‹éç¨‹ã€‚   

> IREEï¼ˆIntermediate Representation Execution Environmentï¼‰æ˜¯ç”± Google èˆ‡é–‹æºç¤¾ç¾¤å…±åŒé–‹ç™¼çš„é«˜æ•ˆèƒ½ç·¨è­¯æ¡†æ¶ï¼Œç”¨ä¾†æŠŠé«˜éšæ©Ÿå™¨å­¸ç¿’æ¨¡å‹è½‰æ›æˆèƒ½åœ¨å„ç¨®ç¡¬é«”ä¸Šç›´æ¥åŸ·è¡Œçš„ç¨‹å¼ç¢¼ã€‚æ¨¡å‹å¯ä»¥å¾ PyTorchã€TensorFlow æˆ–å…¶ä»–å‰ç«¯åŒ¯å‡ºç‚º MLIRï¼ˆMulti-Level Intermediate Representationï¼‰æ ¼å¼ï¼ŒIREE ä¾¿èƒ½åŸºæ–¼é€™äº›ä¸­ä»‹è¡¨ç¤ºé€²è¡Œå„ªåŒ–ã€åˆ†é…è¨˜æ†¶é«”ã€ä¸¦æœ€çµ‚ç”¢ç”Ÿé‡å°ç›®æ¨™ç¡¬é«”ï¼ˆå¦‚ GPUã€CPUã€æˆ–å°ˆç”¨åŠ é€Ÿå™¨ï¼‰çš„åŸ·è¡Œç¨‹å¼ã€‚   

> åœ¨ GPU å¾Œç«¯ä¸­ï¼ŒIREE çš„ Codegen æ¨¡çµ„æœƒé‡å°çŸ©é™£é‹ç®—ï¼ˆå¦‚ linalg.matmulï¼‰ï¼Œè‡ªå‹•æŒ‘é¸åˆé©çš„ MMA intrinsicï¼Œä¸¦æ ¹æ“šç¡¬é«”ç‰¹æ€§ï¼ˆsubgroup å¤§å°ã€å°é½Šæ¢ä»¶ã€shared memory é™åˆ¶ç­‰ï¼‰ç”Ÿæˆæœ€ä½³åŒ–çš„ kernelã€‚é€™ä»½åˆ†ææ–‡ä»¶æœƒé€æ­¥å°æ‡‰ log è¼¸å‡ºèˆ‡å¯¦éš›åŸå§‹ç¢¼ï¼ˆåŒ…å«æª”æ¡ˆåç¨±èˆ‡è¡Œè™Ÿï¼‰ï¼Œé‡ç¾ IREE çš„æ¨å°é‚è¼¯ã€å…¬å¼èˆ‡æ±ºç­–éç¨‹ã€‚å¯ä»¥æ¸…æ¥šçœ‹åˆ° IREE å¦‚ä½•å¾ PyTorch åŒ¯å‡ºçš„ MLIR matmul é‹ç®—ï¼Œä¸€æ­¥æ­¥è½‰æ›æˆèƒ½åœ¨ GPU ä¸Šä»¥ ç¡¬é«”åŸç”Ÿ MMA æŒ‡ä»¤ åŸ·è¡Œçš„é«˜æ•ˆ kernelï¼Œä¸¦ç†è§£ç·¨è­¯å™¨å¦‚ä½•åœ¨ æ¼”ç®—æ³•çµæ§‹ã€ç¡¬é«”ç‰¹æ€§èˆ‡è¨˜æ†¶é«”é…ç½® ä¹‹é–“å–å¾—æœ€ä½³å¹³è¡¡ã€‚   

 --- 
## ğŸ“‹ ç›®éŒ„   
1. [æ¦‚è¿°](/Users/william.mou/Downloads/.md)   
2. [åŸ·è¡Œæµç¨‹ç¸½è¦½](/Users/william.mou/Downloads/.md)   
3. [éšæ®µ 1: Kernel Config é¸æ“‡](/Users/william.mou/Downloads/.md)   
4. [éšæ®µ 2: MMA Schedule Deduction åˆå§‹åŒ–](/Users/william.mou/Downloads/.md)   
5. [éšæ®µ 3: Intrinsic é¸æ“‡èˆ‡é©—è­‰](/Users/william.mou/Downloads/.md)   
6. [éšæ®µ 4: æœ€ä½³ MMA Schedule è¨ˆç®—](/Users/william.mou/Downloads/.md)   
7. [éšæ®µ 5: Schedule é©—è­‰èˆ‡ SRAM æª¢æŸ¥](/Users/william.mou/Downloads/.md)   
8. [éšæ®µ 6: Schedule Fitting](/Users/william.mou/Downloads/.md)   
9. [éšæ®µ 7: æœ€çµ‚é…ç½®](/Users/william.mou/Downloads/.md)   
10. [å®Œæ•´æ±ºç­–æ¨¹](/Users/william.mou/Downloads/.md)   
11. [é—œéµå…¬å¼ç¸½çµ](/Users/william.mou/Downloads/.md)   
 --- 
   
## æ¦‚è¿°   
### æ¸¬è©¦æ¡ˆä¾‹   
**è¼¸å…¥ MLIR**:   
```
linalg.matmul ins(%A, %B : tensor<128x512xf16>, tensor<512x256xf16>) 
              outs(%C : tensor<128x256xf32>) -> tensor<128x256xf32>

```
**å•é¡Œè¦æ ¼**:   
- **çŸ©é™£å¤§å°**: M=128, N=256, K=512   
- **è¼¸å…¥å‹åˆ¥**: f16 Ã— f16   
- **è¼¸å‡ºå‹åˆ¥**: f32   
- **ç›®æ¨™ç¡¬é«”**: AMD RDNA3 (gfx1201)   
- **SRAM é™åˆ¶**: 65536 bytes (64 KB)  
- **IREE ç‰ˆæœ¬**: v3.6.0 
   
**æœ€çµ‚çµæœ**: æˆåŠŸä½¿ç”¨ MMA intrinsic (WMMAR3\_F32\_16x16x16\_F16)   
 --- 
## åŸ·è¡Œæµç¨‹ç¸½è¦½   
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ éšæ®µ 1: Kernel Config é¸æ“‡                                   â”‚
â”‚   é¸æ“‡ VectorDistribution + Contraction Config              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ éšæ®µ 2: MMA Schedule Deduction åˆå§‹åŒ–                        â”‚
â”‚   è¨­å®šå•é¡Œåƒæ•¸ã€SRAM é™åˆ¶ã€é…ç½®é¸é …                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ éšæ®µ 3: Intrinsic é¸æ“‡èˆ‡é©—è­‰ (canTargetIntrinsic)            â”‚
â”‚   âœ“ å‹åˆ¥åŒ¹é…æª¢æŸ¥                                             â”‚
â”‚   âœ“ å°é½Šæª¢æŸ¥                                                 â”‚
â”‚   âœ“ Skinny matmul æª¢æŸ¥                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ éšæ®µ 4: æœ€ä½³ MMA Schedule è¨ˆç®— (getOptimalMMASchedule)       â”‚
â”‚   è¨ˆç®— tile countsã€åˆ†é… subgroups å’Œ tiles                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ éšæ®µ 5: Schedule é©—è­‰èˆ‡ SRAM æª¢æŸ¥ (isValidSchedule)          â”‚
â”‚   âœ“ å°é½Šé©—è­‰                                                 â”‚
â”‚   âœ“ SRAM ä½¿ç”¨é‡è¨ˆç®—                                          â”‚
â”‚   âœ“ SRAM é™åˆ¶æª¢æŸ¥ (50% ä½¿ç”¨ç‡)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ éšæ®µ 6: Schedule Fitting (fitScheduleInSharedMemory)         â”‚
â”‚   âœ“ Schedule å·²ç¶“æœ‰æ•ˆ,ç„¡éœ€ç¸®æ¸› (0 iterations)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ éšæ®µ 7: æœ€çµ‚é…ç½®                                             â”‚
â”‚   Workgroup tile: 64Ã—64, Reduction tile: 128                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```
 --- 
## éšæ®µ 1: Kernel Config é¸æ“‡   
### Log è¼¸å‡º   
```
[iree-llvmgpu-kernel-config]: Selecting root config for: %7 = linalg.matmul ins(%3, %4 : tensor<128x512xf16>, tensor<512x256xf16>) outs(%6 : tensor<128x256xf32>) -> tensor<128x256xf32>
[iree-llvmgpu-kernel-config]: VectorDistribution: finding a suitable config...
[iree-llvmgpu-kernel-config]: VectorDistribution: trying to find a suitable contraction config
[iree-llvmgpu-kernel-config]: Contraction dims: [m, n, k]
[iree-llvmgpu-kernel-config]: Problem size: [128, 256, 512]
[iree-llvmgpu-kernel-config]: Matmul Vector Distribution Config

```
### å°æ‡‰ç¨‹å¼ç¢¼   
**æª”æ¡ˆ**: `compiler/src/iree/compiler/Codegen/LLVMGPU/KernelConfig.cpp`   
**å‡½æ•¸**: `setRootConfig` (è¡Œ 3287-3366)   
```
LogicalResult setRootConfig(mlir::FunctionOpInterface entryPointFn,
                            Operation *computeOp) {
  LDBG("Selecting root config for: " << *computeOp);
  
  auto linalgOp = dyn_cast<linalg::LinalgOp>(computeOp);
  if (!linalgOp) return failure();
  
  // å˜—è©¦ VectorDistribution config
  if (succeeded(setVectorDistributionConfig(target, entryPointFn, linalgOp))) {
    LDBG("VectorDistribution Config");
    return success();
  }
  // ... å…¶ä»– fallback configs
}

```
**å‡½æ•¸**: `setVectorDistributionConfig` (è¡Œ 2800-2900)   
```
static LogicalResult setVectorDistributionConfig(
    IREE::GPU::TargetAttr target, mlir::FunctionOpInterface entryPointFn,
    linalg::LinalgOp op) {
  LDBG("VectorDistribution: finding a suitable config...");
  
  // æª¢æŸ¥æ˜¯å¦ç‚º contraction
  if (linalg::isaContractionOpInterface(op)) {
    LDBG("VectorDistribution: trying to find a suitable contraction config");
    // æå– contraction dimensions
    SmallVector<utils::IteratorType> iteratorTypes = op.getIteratorTypesArray();
    LDBG("Contraction dims: " << contractionDims);
    LDBG("Problem size: " << problemSize);
    
    // å˜—è©¦ä½¿ç”¨ Matmul Vector Distribution
    if (succeeded(setMatmulVectorDistributionConfig(...))) {
      LDBG("Matmul Vector Distribution Config");
      return success();
    }
  }
}

```
### èªªæ˜   
1. **å…¥å£é»**: `setRootConfig` æ˜¯é¸æ“‡ kernel é…ç½®çš„ä¸»è¦å…¥å£   
2. **ç­–ç•¥é¸æ“‡**: å°æ–¼ matmul æ“ä½œ,é¸æ“‡ `VectorDistribution` ç­–ç•¥   
3. **Contraction æª¢æ¸¬**: è­˜åˆ¥å‡ºé€™æ˜¯ä¸€å€‹ contraction æ“ä½œ (matmul)   
4. **ç¶­åº¦æå–**: æå– M, N, K ç¶­åº¦ â†’ [128, 256, 512]   
 --- 
   
## éšæ®µ 2: MMA Schedule Deduction åˆå§‹åŒ–   
### Log è¼¸å‡º   
```
========================================
[DEDUCE MMA] Starting MMA schedule deduction
========================================
deduceMMASchedule: problem types: aType=f16, bType=f16, cType=f32
deduceMMASchedule: problem sizes: M=[128], N=[256], K=[512]
deduceMMASchedule: number of intrinsics: 9
deduceMMASchedule: sharedMemLimitInBytes: 65536
deduceMMASchedule: subgroupSize: 32
deduceMMASchedule: canUpcastAcc: 0
deduceMMASchedule: mustBeAligned: 1
deduceMMASchedule: doCPromotion: 0
========================================

```
### å°æ‡‰ç¨‹å¼ç¢¼   
**æª”æ¡ˆ**: `compiler/src/iree/compiler/Codegen/Common/GPU/GPUHeuristics.cpp`   
**å‡½æ•¸**: `deduceMMASchedule` (è¡Œ 564-672)   
```
FailureOr<GPUMMASchedule> deduceMMASchedule(
    const GPUMatmulShapeType &problem,
    ArrayRef<GPUIntrinsicType> intrinsics,
    const GPUMMAHeuristicSeeds &seeds,
    int64_t sharedMemLimitInBytes,
    int64_t subgroupSize,
    bool transposedLhs,
    bool transposedRhs,
    bool canUpcastAcc,
    bool mustBeAligned,
    bool doCPromotion) {
  
  LLVM_DEBUG({
    llvm::dbgs() << "\n========================================\n";
    llvm::dbgs() << "[DEDUCE MMA] Starting MMA schedule deduction\n";
    llvm::dbgs() << "========================================\n";
    llvm::dbgs() << "deduceMMASchedule: problem types: aType=" << problem.aType
                 << ", bType=" << problem.bType << ", cType=" << problem.cType << "\n";
    llvm::dbgs() << "deduceMMASchedule: problem sizes: M=" << problem.mSizes
                 << ", N=" << problem.nSizes << ", K=" << problem.kSizes << "\n";
    llvm::dbgs() << "deduceMMASchedule: number of intrinsics: " << intrinsics.size() << "\n";
    llvm::dbgs() << "deduceMMASchedule: sharedMemLimitInBytes: " << sharedMemLimitInBytes << "\n";
    llvm::dbgs() << "deduceMMASchedule: subgroupSize: " << subgroupSize << "\n";
    llvm::dbgs() << "deduceMMASchedule: canUpcastAcc: " << canUpcastAcc << "\n";
    llvm::dbgs() << "deduceMMASchedule: mustBeAligned: " << mustBeAligned << "\n";
    llvm::dbgs() << "deduceMMASchedule: doCPromotion: " << doCPromotion << "\n";
  });
  
  // ... ä¸»è¦é‚è¼¯
}

```
### åƒæ•¸èªªæ˜   
|                      åƒæ•¸ |         å€¼ |                               èªªæ˜ |
|:------------------------|:----------|:---------------------------------|
|         `problem.aType` |       f16 |                       LHS çŸ©é™£å…ƒç´ å‹åˆ¥ |
|         `problem.bType` |       f16 |                       RHS çŸ©é™£å…ƒç´ å‹åˆ¥ |
|         `problem.cType` |       f32 |                         è¼¸å‡ºçŸ©é™£å…ƒç´ å‹åˆ¥ |
|        `problem.mSizes` |     [128] |                           M ç¶­åº¦å¤§å° |
|        `problem.nSizes` |     [256] |                           N ç¶­åº¦å¤§å° |
|        `problem.kSizes` |     [512] |                           K ç¶­åº¦å¤§å° |
|     `intrinsics.size()` |         9 |            å¯ç”¨çš„ MMA intrinsics æ•¸é‡ |
| `sharedMemLimitInBytes` |     65536 |                  SRAM é™åˆ¶ (64 KB) |
|          `subgroupSize` |        32 |      Subgroup å¤§å° (AMD Wave size) |
|          `canUpcastAcc` | 0 (false) |                   æ˜¯å¦å…è¨±ç´¯åŠ å™¨ upcast |
|         `mustBeAligned` |  1 (true) |                           æ˜¯å¦å¿…é ˆå°é½Š |
|          `doCPromotion` | 0 (false) |                 æ˜¯å¦å°‡ C çŸ©é™£æå‡åˆ° SRAM |

### èªªæ˜   
1. **å•é¡Œå®šç¾©**: å»ºç«‹ `GPUMatmulShapeType` çµæ§‹æè¿°å•é¡Œ   
2. **Intrinsics è¼‰å…¥**: å¾ target (gfx1201) è¼‰å…¥ 9 å€‹å¯ç”¨çš„ MMA intrinsics   
3. **SRAM é™åˆ¶**: å¾ç¡¬é«”è¦æ ¼ç²å– shared memory é™åˆ¶ (64 KB)   
4. **é…ç½®é¸é …**: è¨­å®šå°é½Šè¦æ±‚ã€upcast é¸é …ç­‰   
 --- 
   
## éšæ®µ 3: Intrinsic é¸æ“‡èˆ‡é©—è­‰   
### Log è¼¸å‡º   
```
[DEDUCE MMA] ========== Intrinsic 1/9 ==========
Trying intrinsic: aType=f16, bType=f16, cType=f32, M=[16], N=[16], K=[16]
[CAN TARGET] Checking if intrinsic can be used:
[CAN TARGET]   Problem: aType=f16, bType=f16, cType=f32
[CAN TARGET]   Intrinsic: aType=f16, bType=f16, cType=f32
[CAN TARGET] âœ“ Input types match
[CAN TARGET] âœ“ Output type matches
[CAN TARGET] Alignment check (mustBeAligned=1):
[CAN TARGET]   M: 128 % 16 = 0 âœ“
[CAN TARGET]   N: 256 % 16 = 0 âœ“
[CAN TARGET]   K: 512 % 16 = 0 âœ“
[CAN TARGET] âœ“ All dimensions aligned
[DEDUCE MMA] -> canTargetIntrinsic succeeded

```
### å°æ‡‰ç¨‹å¼ç¢¼   
**æª”æ¡ˆ**: `compiler/src/iree/compiler/Codegen/Common/GPU/GPUHeuristics.cpp`   
**å‡½æ•¸**: `canTargetIntrinsic` (è¡Œ 290-406)   
```
static LogicalResult canTargetIntrinsic(
    const GPUMatmulShapeType &problem,
    const GPUMatmulShapeType &intrinsic,
    int64_t preferredSubgroupSize,
    bool canUpcastAcc,
    bool mustBeAligned) {
  
  LLVM_DEBUG({
    llvm::dbgs() << "[CAN TARGET] Checking if intrinsic can be used:\n";
    llvm::dbgs() << "[CAN TARGET]   Problem: aType=" << problem.aType
                 << ", bType=" << problem.bType << ", cType=" << problem.cType << "\n";
    llvm::dbgs() << "[CAN TARGET]   Intrinsic: aType=" << intrinsic.aType
                 << ", bType=" << intrinsic.bType << ", cType=" << intrinsic.cType << "\n";
  });
  
  // 1. æª¢æŸ¥è¼¸å…¥å‹åˆ¥ (A å’Œ B)
  if (problem.aType != intrinsic.aType || problem.bType != intrinsic.bType) {
    LLVM_DEBUG(llvm::dbgs() << "[CAN TARGET] âŒ FAILED: Input type mismatch\n");
    return failure();
  }
  LLVM_DEBUG(llvm::dbgs() << "[CAN TARGET] âœ“ Input types match\n");
  
  // 2. æª¢æŸ¥è¼¸å‡ºå‹åˆ¥ (C)
  if (problem.cType != intrinsic.cType) {
    bool isFpCase = isa<FloatType>(problem.cType) && isa<FloatType>(intrinsic.cType);
    bool isUpcast = problem.cType.getIntOrFloatBitWidth() <
                    intrinsic.cType.getIntOrFloatBitWidth();
    if (!(canUpcastAcc && isFpCase && isUpcast)) {
      LLVM_DEBUG(llvm::dbgs() << "[CAN TARGET] âŒ FAILED: Cannot upcast accumulator\n");
      return failure();
    }
    LLVM_DEBUG(llvm::dbgs() << "[CAN TARGET] âœ“ Accumulator upcast allowed\n");
  } else {
    LLVM_DEBUG(llvm::dbgs() << "[CAN TARGET] âœ“ Output type matches\n");
  }
  
  // 3. æª¢æŸ¥å°é½Š
  if (mustBeAligned) {
    int64_t mRemainder = problem.mSizes.back() % intrinsic.mSizes[0];
    int64_t nRemainder = problem.nSizes.back() % intrinsic.nSizes[0];
    int64_t kRemainder = problem.kSizes.back() % intrinsic.kSizes[0];
    
    LLVM_DEBUG({
      llvm::dbgs() << "[CAN TARGET] Alignment check (mustBeAligned=" << mustBeAligned << "):\n";
      llvm::dbgs() << "[CAN TARGET]   M: " << problem.mSizes.back()
                   << " % " << intrinsic.mSizes[0] << " = " << mRemainder;
      if (mRemainder == 0) llvm::dbgs() << " âœ“\n"; else llvm::dbgs() << " âŒ\n";
      // ... N å’Œ K çš„æª¢æŸ¥
    });
    
    if (mRemainder != 0 || nRemainder != 0 || kRemainder != 0) {
      LLVM_DEBUG(llvm::dbgs() << "[CAN TARGET] âŒ FAILED: Alignment check failed\n");
      return failure();
    }
    LLVM_DEBUG(llvm::dbgs() << "[CAN TARGET] âœ“ All dimensions aligned\n");
  }
  
  LLVM_DEBUG(llvm::dbgs() << "[CAN TARGET] âœ“âœ“âœ“ SUCCESS: Intrinsic can be used!\n");
  return success();
}

```
### æª¢æŸ¥æµç¨‹   
### 1. è¼¸å…¥å‹åˆ¥åŒ¹é…   
```
Problem:    aType=f16, bType=f16
Intrinsic:  aType=f16, bType=f16
Result:     âœ“ Match

```
### 2. è¼¸å‡ºå‹åˆ¥åŒ¹é…   
```
Problem:    cType=f32
Intrinsic:  cType=f32
Result:     âœ“ Match (å®Œå…¨ç›¸åŒ,ä¸éœ€è¦ upcast)

```
### 3. å°é½Šæª¢æŸ¥   
```
M: 128 % 16 = 0  âœ“
N: 256 % 16 = 0  âœ“
K: 512 % 16 = 0  âœ“

```
**å°é½Šå…¬å¼**:   
```
remainder = problem_size % intrinsic_size
aligned = (remainder == 0)

```
### é¸ä¸­çš„ Intrinsic   
**WMMAR3\_F32\_16x16x16\_F16**:   
- **è¼¸å…¥**: f16 Ã— f16   
- **è¼¸å‡º**: f32   
- **å¤§å°**: 16Ã—16Ã—16   
- **ä¾†æº**: AMD RDNA3 WMMA (Wave Matrix Multiply-Accumulate)   
 --- 
   
## éšæ®µ 4: æœ€ä½³ MMA Schedule è¨ˆç®—   
### Log è¼¸å‡º   
```
[GET OPTIMAL] Computing optimal MMA schedule
[GET OPTIMAL] Problem: M=[128], N=[256], K=[512]
[GET OPTIMAL] Intrinsic: M=16, N=16, K=16
[GET OPTIMAL] Seeds: bestSubgroupCountPerWorkgroup=4, bestMNTileCountPerSubgroup=4, bestKElementCountPerSubgroup=0
[GET OPTIMAL] Total tile counts:
[GET OPTIMAL]   M: 128 / 16 = 8 tiles
[GET OPTIMAL]   N: 256 / 16 = 16 tiles

[DEDUCE MMA] chosen MMA schedule:
  mSizes: 16, nSizes: 16, kSizes: 16, mTileSizes: [2], nTileSizes: [2], kTileSizes: [8], mSubgroupCounts: [2], nSubgroupCounts: [2]

```
### å°æ‡‰ç¨‹å¼ç¢¼   
**æª”æ¡ˆ**: `compiler/src/iree/compiler/Codegen/Common/GPU/GPUHeuristics.cpp`   
**å‡½æ•¸**: `getOptimalMMASchedule` (è¡Œ 442-562)   
```
static GPUMMASchedule getOptimalMMASchedule(
    const GPUMatmulShapeType &problem,
    const GPUIntrinsicType &intrinsic,
    const GPUMMAHeuristicSeeds &seeds) {
  
  LLVM_DEBUG({
    llvm::dbgs() << "[GET OPTIMAL] Computing optimal MMA schedule\n";
    llvm::dbgs() << "[GET OPTIMAL] Problem: M=" << problem.mSizes
                 << ", N=" << problem.nSizes << ", K=" << problem.kSizes << "\n";
    llvm::dbgs() << "[GET OPTIMAL] Intrinsic: M=" << intrinsic.mSizes[0]
                 << ", N=" << intrinsic.nSizes[0] << ", K=" << intrinsic.kSizes[0] << "\n";
    llvm::dbgs() << "[GET OPTIMAL] Seeds: bestSubgroupCountPerWorkgroup="
                 << seeds.bestSubgroupCountPerWorkgroup
                 << ", bestMNTileCountPerSubgroup=" << seeds.bestMNTileCountPerSubgroup
                 << ", bestKElementCountPerSubgroup=" << seeds.bestKElementCountPerSubgroup << "\n";
  });
  
  // è¨ˆç®—ç¸½ tile æ•¸é‡
  SmallVector<int64_t, 2> mTotalTileCounts = problem.mSizes;
  SmallVector<int64_t, 2> nTotalTileCounts = problem.nSizes;
  mTotalTileCounts.back() = llvm::divideCeil(problem.mSizes.back(), intrinsic.mSizes[0]);
  nTotalTileCounts.back() = llvm::divideCeil(problem.nSizes.back(), intrinsic.nSizes[0]);
  
  LLVM_DEBUG({
    llvm::dbgs() << "[GET OPTIMAL] Total tile counts:\n";
    llvm::dbgs() << "[GET OPTIMAL]   M: " << problem.mSizes.back() << " / "
                 << intrinsic.mSizes[0] << " = " << mTotalTileCounts.back() << " tiles\n";
    llvm::dbgs() << "[GET OPTIMAL]   N: " << problem.nSizes.back() << " / "
                 << intrinsic.nSizes[0] << " = " << nTotalTileCounts.back() << " tiles\n";
  });
  
  // ä½¿ç”¨ GCD ç®—æ³•åˆ†é… subgroups å’Œ tiles
  int64_t remainingSubgroups = seeds.bestSubgroupCountPerWorkgroup;  // 4
  int64_t remainingTiles = seeds.bestMNTileCountPerSubgroup;         // 4
  
  // ... GCD åˆ†é…é‚è¼¯ (è¦‹ä¸‹æ–¹è©³ç´°èªªæ˜)
  
  SmallVector<int64_t> kTileSizes = getBestKTileSizes(problem, intrinsic, seeds);
  
  return GPUMMASchedule{
      intrinsic.mmaKind,
      intrinsic.mSizes[0],  // 16
      intrinsic.nSizes[0],  // 16
      intrinsic.kSizes[0],  // 16
      mSubgroupCounts,      // [2]
      nSubgroupCounts,      // [2]
      mTileSizes,           // [2]
      nTileSizes,           // [2]
      kTileSizes            // [8]
  };
}

```
### è¨ˆç®—éç¨‹è©³è§£   
### 1. Total Tile Counts è¨ˆç®—   
```
M æ–¹å‘: 128 / 16 = 8 tiles
N æ–¹å‘: 256 / 16 = 16 tiles

```
**æ„ç¾©**: éœ€è¦å¤šå°‘å€‹ 16Ã—16 çš„ MMA intrinsic æ‰èƒ½è¦†è“‹æ•´å€‹çŸ©é™£   
### 2. Subgroup å’Œ Tile åˆ†é… (ä½¿ç”¨ GCD ç®—æ³•)   
**åˆå§‹å€¼**:   
- `remainingSubgroups` = 4 (æ¯å€‹ workgroup æœ‰ 4 å€‹ subgroups)   
- `remainingTiles` = 4 (æ¯å€‹ subgroup æœ‰ 4 å€‹ tiles)   
   
**M æ–¹å‘åˆ†é…**:   
```
mTotalTileCounts = 8
GCD(8, 4) = 4
ä½†ä½¿ç”¨ sqrt ç­–ç•¥: sqrt(4) = 2

mSubgroupCounts = 2
mTileSizes = 2

é©—è­‰: 2 (subgroups) Ã— 2 (tiles/subgroup) Ã— 16 (intrinsic size) = 64

```
**N æ–¹å‘åˆ†é…**:   
```
nTotalTileCounts = 16
GCD(16, 2) = 2  (remainingSubgroups å·²ç”¨æ‰ä¸€åŠ)

nSubgroupCounts = 2
nTileSizes = 2

é©—è­‰: 2 (subgroups) Ã— 2 (tiles/subgroup) Ã— 16 (intrinsic size) = 64

```
**K æ–¹å‘åˆ†é…**:   
```
kTotalTileCounts = 512 / 16 = 32
bestKElementCountPerSubgroup = 128 (å¾ seeds)
kTileCountPerSubgroup = 128 / 16 = 8

kTileSizes = 8

é©—è­‰: 8 (tiles) Ã— 16 (intrinsic size) = 128

```
### 3. æœ€çµ‚ Schedule   
```
mSizes: 16              â† MMA intrinsic M å¤§å°
nSizes: 16              â† MMA intrinsic N å¤§å°
kSizes: 16              â† MMA intrinsic K å¤§å°
mSubgroupCounts: [2]    â† M æ–¹å‘ 2 å€‹ subgroups
nSubgroupCounts: [2]    â† N æ–¹å‘ 2 å€‹ subgroups
mTileSizes: [2]         â† æ¯å€‹ subgroup 2 å€‹ M tiles
nTileSizes: [2]         â† æ¯å€‹ subgroup 2 å€‹ N tiles
kTileSizes: [8]         â† æ¯å€‹ subgroup 8 å€‹ K tiles

```
 --- 
## éšæ®µ 5: Schedule é©—è­‰èˆ‡ SRAM æª¢æŸ¥   
### Log è¼¸å‡º   
```
[VALIDATE SCHEDULE] Validating schedule...
[VALIDATE SCHEDULE] Bitwidths: LHS=16, RHS=16, Result=32
[IREE MMA DEBUG] isValidMMASchedule: subgroupSize=32, bBits=16, elemsPerThread(128b/B)=8, wgThreads=128, mWgSize=64, nWgSize=64, kWgSize=128, innerLhsDimSize=128, innerRhsDimSize=64
[VALIDATE SCHEDULE] Alignment check: PASS
[SRAM CALC] calculateOperandsSharedMemoryUsedInBytes:
  tileM = 16 * 2 * 2 = 64
  tileN = 16 * 2 * 2 = 64
  tileK = 16 * 8 = 128
  LHS SRAM = 64 * 128 * 16 bits / 8 = 16384 bytes
  RHS SRAM = 64 * 128 * 16 bits / 8 = 16384 bytes
  Total Operands SRAM = 32768 bytes
[VALIDATE SCHEDULE] ========== SRAM Summary ==========
[VALIDATE SCHEDULE] Available Shared Memory: 65536 bytes
[VALIDATE SCHEDULE] Predicted Shared Memory Used by Schedule: 32768 bytes
[VALIDATE SCHEDULE] Usage: 32768 / 65536 = 5.000000e+01%
[VALIDATE SCHEDULE] SRAM Check: PASS
[VALIDATE SCHEDULE] Overall: VALID
[VALIDATE SCHEDULE] =====================================

```
### å°æ‡‰ç¨‹å¼ç¢¼   
**æª”æ¡ˆ**: `compiler/src/iree/compiler/Codegen/Common/GPU/GPUHeuristics.cpp`   
**Lambda å‡½æ•¸**: `isValidSchedule` (åœ¨ `deduceMMASchedule` å…§,è¡Œ 597-620)   
```
auto isValidSchedule = [&](const GPUMMASchedule &schedule) -> bool {
  LLVM_DEBUG(llvm::dbgs() << "[VALIDATE SCHEDULE] Validating schedule...\n");
  
  int64_t lhsBitwidth = intrinsic.aType.getIntOrFloatBitWidth();  // 16
  int64_t rhsBitwidth = intrinsic.bType.getIntOrFloatBitWidth();  // 16
  int64_t resultBitwidth = intrinsic.cType.getIntOrFloatBitWidth();  // 32
  
  LLVM_DEBUG({
    llvm::dbgs() << "[VALIDATE SCHEDULE] Bitwidths: LHS=" << lhsBitwidth
                 << ", RHS=" << rhsBitwidth << ", Result=" << resultBitwidth << "\n";
  });
  
  // 1. å°é½Šæª¢æŸ¥
  bool isAligned = isValidMMASchedule(problem, schedule, mustBeAligned,
                                      subgroupSize, transposedLhs, transposedRhs);
  LLVM_DEBUG({
    llvm::dbgs() << "[VALIDATE SCHEDULE] Alignment check: "
                 << (isAligned ? "PASS" : "FAIL") << "\n";
  });
  
  // 2. SRAM ä½¿ç”¨é‡è¨ˆç®—
  int64_t sharedMemoryUsed = calculateOperandsSharedMemoryUsedInBytes(
      schedule, lhsBitwidth, rhsBitwidth);
  
  if (doCPromotion) {
    int64_t resultSRAM = calculateResultSharedMemoryUsedInBytes(schedule, resultBitwidth);
    sharedMemoryUsed += resultSRAM;
  }
  
  // 3. SRAM é™åˆ¶æª¢æŸ¥
  LLVM_DEBUG({
    llvm::dbgs() << "[VALIDATE SCHEDULE] ========== SRAM Summary ==========\n";
    llvm::dbgs() << "[VALIDATE SCHEDULE] Available Shared Memory: "
                 << sharedMemLimitInBytes << " bytes\n";
    llvm::dbgs() << "[VALIDATE SCHEDULE] Predicted Shared Memory Used by Schedule: "
                 << sharedMemoryUsed << " bytes\n";
    llvm::dbgs() << "[VALIDATE SCHEDULE] Usage: " << sharedMemoryUsed << " / "
                 << sharedMemLimitInBytes << " = "
                 << (100.0 * sharedMemoryUsed / sharedMemLimitInBytes) << "%\n";
    llvm::dbgs() << "[VALIDATE SCHEDULE] SRAM Check: "
                 << (sharedMemoryUsed <= sharedMemLimitInBytes ? "PASS" : "FAIL") << "\n";
    llvm::dbgs() << "[VALIDATE SCHEDULE] Overall: "
                 << (isAligned && sharedMemoryUsed <= sharedMemLimitInBytes ? "VALID" : "INVALID") << "\n";
  });
  
  return isAligned && sharedMemoryUsed <= sharedMemLimitInBytes;
};

```
**å‡½æ•¸**: `calculateOperandsSharedMemoryUsedInBytes` (è¡Œ 52-81)   
```
static int64_t calculateOperandsSharedMemoryUsedInBytes(
    const GPUMMASchedule &schedule,
    int64_t lhsBitwidth,
    int64_t rhsBitwidth) {
  
  // è¨ˆç®— workgroup tile å¤§å°
  int64_t tileM = schedule.mSize * prod(schedule.mTileSizes) * prod(schedule.mSubgroupCounts);
  int64_t tileN = schedule.nSize * prod(schedule.nTileSizes) * prod(schedule.nSubgroupCounts);
  int64_t tileK = schedule.kSize * prod(schedule.kTileSizes);
  
  // è¨ˆç®— SRAM ä½¿ç”¨é‡
  int64_t lhsBytes = (tileM * tileK * lhsBitwidth) / 8;
  int64_t rhsBytes = (tileN * tileK * rhsBitwidth) / 8;
  int64_t totalBytes = lhsBytes + rhsBytes;
  
  LLVM_DEBUG({
    llvm::dbgs() << "[SRAM CALC] calculateOperandsSharedMemoryUsedInBytes:\n";
    llvm::dbgs() << "  tileM = " << schedule.mSize << " * " << prod(schedule.mTileSizes)
                 << " * " << prod(schedule.mSubgroupCounts) << " = " << tileM << "\n";
    llvm::dbgs() << "  tileN = " << schedule.nSize << " * " << prod(schedule.nTileSizes)
                 << " * " << prod(schedule.nSubgroupCounts) << " = " << tileN << "\n";
    llvm::dbgs() << "  tileK = " << schedule.kSize << " * " << prod(schedule.kTileSizes)
                 << " = " << tileK << "\n";
    llvm::dbgs() << "  LHS SRAM = " << tileM << " * " << tileK << " * " << lhsBitwidth
                 << " bits / 8 = " << lhsBytes << " bytes\n";
    llvm::dbgs() << "  RHS SRAM = " << tileN << " * " << tileK << " * " << rhsBitwidth
                 << " bits / 8 = " << rhsBytes << " bytes\n";
    llvm::dbgs() << "  Total Operands SRAM = " << totalBytes << " bytes\n";
  });
  
  return totalBytes;
}

```
### SRAM è¨ˆç®—è©³è§£   
### 1. Tile å¤§å°è¨ˆç®—   
```
tileM = mSize Ã— prod(mTileSizes) Ã— prod(mSubgroupCounts)
      = 16 Ã— 2 Ã— 2
      = 64

tileN = nSize Ã— prod(nTileSizes) Ã— prod(nSubgroupCounts)
      = 16 Ã— 2 Ã— 2
      = 64

tileK = kSize Ã— prod(kTileSizes)
      = 16 Ã— 8
      = 128

```
**æ„ç¾©**: æ¯å€‹ workgroup è™•ç†çš„çŸ©é™£å¡Šå¤§å°   
### 2. LHS SRAM è¨ˆç®—   
```
LHS çŸ©é™£å¤§å°: tileM Ã— tileK = 64 Ã— 128
å…ƒç´ å‹åˆ¥: f16 (16 bits)

LHS SRAM = 64 Ã— 128 Ã— 16 bits / 8
         = 64 Ã— 128 Ã— 2 bytes
         = 16384 bytes

```
### 3. RHS SRAM è¨ˆç®—   
```
RHS çŸ©é™£å¤§å°: tileN Ã— tileK = 64 Ã— 128
å…ƒç´ å‹åˆ¥: f16 (16 bits)

RHS SRAM = 64 Ã— 128 Ã— 16 bits / 8
         = 64 Ã— 128 Ã— 2 bytes
         = 16384 bytes

```
### 4. ç¸½ SRAM ä½¿ç”¨é‡   
```
Total SRAM = LHS SRAM + RHS SRAM
           = 16384 + 16384
           = 32768 bytes

```
### 5. SRAM ä½¿ç”¨ç‡   
```
Usage = 32768 / 65536 Ã— 100%
      = 50%

```
**çµæœ**: PASS (ä½¿ç”¨ç‡ 50%,é ä½æ–¼ 100% é™åˆ¶)   
 --- 
## éšæ®µ 6: Schedule Fitting   
### Log è¼¸å‡º   
```
[DEDUCE MMA] Calling fitScheduleInSharedMemory...

[FIT SCHEDULE] Entering fitScheduleInSharedMemory
[FIT SCHEDULE] Initial schedule: mSizes: 16, nSizes: 16, kSizes: 16, mTileSizes: [2], nTileSizes: [2], kTileSizes: [8], mSubgroupCounts: [2], nSubgroupCounts: [2]
[FIT SCHEDULE] SUCCESS: Schedule is valid after 0 iterations
[FIT SCHEDULE] Final schedule: mSizes: 16, nSizes: 16, kSizes: 16, mTileSizes: [2], nTileSizes: [2], kTileSizes: [8], mSubgroupCounts: [2], nSubgroupCounts: [2]

```
### å°æ‡‰ç¨‹å¼ç¢¼   
**æª”æ¡ˆ**: `compiler/src/iree/compiler/Codegen/Common/GPU/GPUHeuristics.cpp`   
**å‡½æ•¸**: `fitScheduleInSharedMemory` (è¡Œ 210-288)   
```
static FailureOr<GPUMMASchedule> fitScheduleInSharedMemory(
    GPUMatmulShapeType intrinsic,
    GPUMMASchedule schedule,
    llvm::function_ref<bool(const GPUMMASchedule &schedule)> isScheduleValid) {
  
  LLVM_DEBUG({
    llvm::dbgs() << "[FIT SCHEDULE] Entering fitScheduleInSharedMemory\n";
    llvm::dbgs() << "[FIT SCHEDULE] Initial schedule: " << schedule << "\n";
  });
  
  int iteration = 0;
  while (!isScheduleValid(schedule)) {
    iteration++;
    LLVM_DEBUG({
      llvm::dbgs() << "[FIT SCHEDULE] Iteration " << iteration << ": Schedule is invalid\n";
      llvm::dbgs() << "[FIT SCHEDULE] Attempting to shrink schedule...\n";
    });
    
    // å˜—è©¦ç¸®æ¸›ç¶­åº¦ (æŒ‰å„ªå…ˆé †åº)
    if (succeeded(decrementIfPossible(schedule.mTileSizes, "mTileSizes"))) continue;
    if (succeeded(decrementIfPossible(schedule.nTileSizes, "nTileSizes"))) continue;
    if (succeeded(decrementIfPossible(schedule.kTileSizes, "kTileSizes"))) continue;
    if (succeeded(decrementIfPossible(schedule.mSubgroupCounts, "mSubgroupCounts"))) continue;
    if (succeeded(decrementIfPossible(schedule.nSubgroupCounts, "nSubgroupCounts"))) continue;
    
    // ç„¡æ³•ç¸®æ¸›,å¤±æ•—
    LLVM_DEBUG(llvm::dbgs() << "[FIT SCHEDULE] ERROR: Cannot shrink any dimension further!\n");
    return failure();
  }
  
  LLVM_DEBUG({
    llvm::dbgs() << "[FIT SCHEDULE] SUCCESS: Schedule is valid after " << iteration << " iterations\n";
    llvm::dbgs() << "[FIT SCHEDULE] Final schedule: " << schedule << "\n";
  });
  
  return schedule;
}

```
### èªªæ˜   
**æœ¬æ¡ˆä¾‹**: Schedule åœ¨ç¬¬ä¸€æ¬¡é©—è­‰æ™‚å°±é€šéäº†,å› æ­¤:   
- **è¿­ä»£æ¬¡æ•¸**: 0   
- **ç¸®æ¸›æ“ä½œ**: ç„¡   
- **çµæœ**: ç›´æ¥è¿”å›åŸå§‹ schedule   
   
**å¦‚æœéœ€è¦ç¸®æ¸›**: æœƒæŒ‰ä»¥ä¸‹é †åºå˜—è©¦:   
1. `mTileSizes`: [2] â†’ [1]   
2. `nTileSizes`: [2] â†’ [1]   
3. `kTileSizes`: [8] â†’ [7] â†’ [6] â†’ ...   
4. `mSubgroupCounts`: [2] â†’ [1]   
5. `nSubgroupCounts`: [2] â†’ [1]   
 --- 
   
## éšæ®µ 7: æœ€çµ‚é…ç½®   
### Log è¼¸å‡º   
```
[iree-llvmgpu-kernel-config]: Target Subgroup size: 32
[iree-llvmgpu-kernel-config]: Schedule: mSizes: 16, nSizes: 16, kSizes: 16, mTileSizes: [2], nTileSizes: [2], kTileSizes: [8], mSubgroupCounts: [2], nSubgroupCounts: [2]
[iree-llvmgpu-kernel-config]: Contraction dims: [m, n, k]
[iree-llvmgpu-kernel-config]: Workgroup tile sizes: [64, 64, 0]
[iree-llvmgpu-kernel-config]: Contraction dims: [m, n, k]
[iree-llvmgpu-kernel-config]: Reduction tile sizes: [0, 0, 128]

```
### å°æ‡‰ç¨‹å¼ç¢¼   
**æª”æ¡ˆ**: `compiler/src/iree/compiler/Codegen/LLVMGPU/KernelConfig.cpp`   
**å‡½æ•¸**: `setMatmulVectorDistributionConfig` (è¡Œ 1322-1450)   
```
static LogicalResult setMatmulVectorDistributionConfig(
    IREE::GPU::TargetAttr target,
    mlir::FunctionOpInterface entryPointFn,
    linalg::LinalgOp op) {
  
  // ... å‰é¢çš„ MMA schedule deduction
  
  // å¾ schedule è¨ˆç®— workgroup tile sizes
  SmallVector<int64_t> workgroupTileSizes(numLoops, 0);
  workgroupTileSizes[mDim] = schedule->mSize * schedule->mTileSizes[0] *
                              schedule->mSubgroupCounts[0];  // 16 Ã— 2 Ã— 2 = 64
  workgroupTileSizes[nDim] = schedule->nSize * schedule->nTileSizes[0] *
                              schedule->nSubgroupCounts[0];  // 16 Ã— 2 Ã— 2 = 64
  
  LDBG("Workgroup tile sizes: " << workgroupTileSizes);
  
  // è¨ˆç®— reduction tile sizes
  SmallVector<int64_t> reductionTileSizes(numLoops, 0);
  reductionTileSizes[kDim] = schedule->kSize * schedule->kTileSizes[0];  // 16 Ã— 8 = 128
  
  LDBG("Reduction tile sizes: " << reductionTileSizes);
  
  // è¨­å®š lowering config
  auto config = IREE::GPU::LoweringConfigAttr::get(context, tilingConfig);
  setLoweringConfig(op, config);
  
  return success();
}

```
### æœ€çµ‚é…ç½®ç¸½çµ   
|                         é…ç½®é … |          å€¼ |                       è¨ˆç®—æ–¹å¼ |
|:----------------------------|:-----------|:---------------------------|
|        **Workgroup Tile M** |         64 |                 16 Ã— 2 Ã— 2 |
|        **Workgroup Tile N** |         64 |                 16 Ã— 2 Ã— 2 |
|        **Reduction Tile K** |        128 |                     16 Ã— 8 |
|           **Subgroup Size** |         32 |              AMD Wave size |
| **Subgroups per Workgroup** |          4 |              2 (M) Ã— 2 (N) |
|   **Threads per Workgroup** |        128 |                     32 Ã— 4 |
|           **MMA Intrinsic** |   16Ã—16Ã—16 | WMMAR3\_F32\_16x16x16\_F16 |

### Workgroup åˆ†ä½ˆ   
```
æ•´å€‹çŸ©é™£ (128Ã—256):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WG(0,0) â”‚ WG(0,1) â”‚ WG(0,2) â”‚ WG(0,3) â”‚  â† æ¯å€‹ WG æ˜¯ 64Ã—64
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ WG(1,0) â”‚ WG(1,1) â”‚ WG(1,2) â”‚ WG(1,3) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Workgroup æ•¸é‡:
- M æ–¹å‘: 128 / 64 = 2
- N æ–¹å‘: 256 / 64 = 4
- ç¸½å…±: 2 Ã— 4 = 8 å€‹ workgroups

```
 --- 
## å®Œæ•´æ±ºç­–æ¨¹   
```
setRootConfig
  â”‚
  â”œâ”€> setVectorDistributionConfig
  â”‚     â”‚
  â”‚     â”œâ”€> æª¢æ¸¬ Contraction æ“ä½œ âœ“
  â”‚     â”‚
  â”‚     â””â”€> setMatmulVectorDistributionConfig
  â”‚           â”‚
  â”‚           â””â”€> deduceMMASchedule
  â”‚                 â”‚
  â”‚                 â”œâ”€> åˆå§‹åŒ–åƒæ•¸
  â”‚                 â”‚   â”œâ”€> problem: M=128, N=256, K=512, f16Ã—f16â†’f32
  â”‚                 â”‚   â”œâ”€> intrinsics: 9 å€‹å¯ç”¨
  â”‚                 â”‚   â”œâ”€> SRAM limit: 65536 bytes
  â”‚                 â”‚   â””â”€> mustBeAligned: true
  â”‚                 â”‚
  â”‚                 â”œâ”€> For each intrinsic (å˜—è©¦ç¬¬ 1 å€‹):
  â”‚                 â”‚     â”‚
  â”‚                 â”‚     â”œâ”€> canTargetIntrinsic
  â”‚                 â”‚     â”‚     â”œâ”€> æª¢æŸ¥è¼¸å…¥å‹åˆ¥: f16 vs f16 âœ“
  â”‚                 â”‚     â”‚     â”œâ”€> æª¢æŸ¥è¼¸å‡ºå‹åˆ¥: f32 vs f32 âœ“
  â”‚                 â”‚     â”‚     â”œâ”€> æª¢æŸ¥å°é½Š:
  â”‚                 â”‚     â”‚     â”‚   â”œâ”€> M: 128 % 16 = 0 âœ“
  â”‚                 â”‚     â”‚     â”‚   â”œâ”€> N: 256 % 16 = 0 âœ“
  â”‚                 â”‚     â”‚     â”‚   â””â”€> K: 512 % 16 = 0 âœ“
  â”‚                 â”‚     â”‚     â””â”€> âœ“ SUCCESS
  â”‚                 â”‚     â”‚
  â”‚                 â”‚     â”œâ”€> getOptimalMMASchedule
  â”‚                 â”‚     â”‚     â”œâ”€> è¨ˆç®— total tile counts:
  â”‚                 â”‚     â”‚     â”‚   â”œâ”€> M: 128/16 = 8 tiles
  â”‚                 â”‚     â”‚     â”‚   â””â”€> N: 256/16 = 16 tiles
  â”‚                 â”‚     â”‚     â”œâ”€> ä½¿ç”¨ GCD åˆ†é…:
  â”‚                 â”‚     â”‚     â”‚   â”œâ”€> mSubgroupCounts = 2
  â”‚                 â”‚     â”‚     â”‚   â”œâ”€> nSubgroupCounts = 2
  â”‚                 â”‚     â”‚     â”‚   â”œâ”€> mTileSizes = 2
  â”‚                 â”‚     â”‚     â”‚   â”œâ”€> nTileSizes = 2
  â”‚                 â”‚     â”‚     â”‚   â””â”€> kTileSizes = 8
  â”‚                 â”‚     â”‚     â””â”€> è¿”å› schedule
  â”‚                 â”‚     â”‚
  â”‚                 â”‚     â””â”€> fitScheduleInSharedMemory
  â”‚                 â”‚           â”‚
  â”‚                 â”‚           â”œâ”€> isValidSchedule (lambda)
  â”‚                 â”‚           â”‚     â”œâ”€> å°é½Šæª¢æŸ¥: PASS âœ“
  â”‚                 â”‚           â”‚     â”œâ”€> calculateOperandsSharedMemoryUsedInBytes
  â”‚                 â”‚           â”‚     â”‚     â”œâ”€> tileM = 16Ã—2Ã—2 = 64
  â”‚                 â”‚           â”‚     â”‚     â”œâ”€> tileN = 16Ã—2Ã—2 = 64
  â”‚                 â”‚           â”‚     â”‚     â”œâ”€> tileK = 16Ã—8 = 128
  â”‚                 â”‚           â”‚     â”‚     â”œâ”€> LHS SRAM = 64Ã—128Ã—2 = 16384 bytes
  â”‚                 â”‚           â”‚     â”‚     â”œâ”€> RHS SRAM = 64Ã—128Ã—2 = 16384 bytes
  â”‚                 â”‚           â”‚     â”‚     â””â”€> Total = 32768 bytes
  â”‚                 â”‚           â”‚     â”œâ”€> SRAM æª¢æŸ¥: 32768 <= 65536 âœ“
  â”‚                 â”‚           â”‚     â””â”€> è¿”å› VALID
  â”‚                 â”‚           â”‚
  â”‚                 â”‚           â”œâ”€> Schedule å·²ç¶“æœ‰æ•ˆ,ç„¡éœ€ç¸®æ¸›
  â”‚                 â”‚           â””â”€> âœ“ SUCCESS (0 iterations)
  â”‚                 â”‚
  â”‚                 â””â”€> âœ“ è¿”å› valid schedule
  â”‚
  â””â”€> âœ“ è¨­å®šæœ€çµ‚é…ç½®
        â”œâ”€> Workgroup tile: [64, 64, 0]
        â”œâ”€> Reduction tile: [0, 0, 128]
        â””â”€> Subgroup size: 32

```
 --- 
## é—œéµå…¬å¼ç¸½çµ   
### 1. Tile Counts è¨ˆç®—   
```
mTotalTileCounts = ceil(problem.mSize / intrinsic.mSize)
nTotalTileCounts = ceil(problem.nSize / intrinsic.nSize)
kTotalTileCounts = ceil(problem.kSize / intrinsic.kSize)

```
**æœ¬æ¡ˆä¾‹**:   
```
M: ceil(128 / 16) = 8
N: ceil(256 / 16) = 16
K: ceil(512 / 16) = 32

```
### 2. Workgroup Tile Size è¨ˆç®—   
```
workgroupTileM = mSize Ã— mTileSizes Ã— mSubgroupCounts
workgroupTileN = nSize Ã— nTileSizes Ã— nSubgroupCounts
workgroupTileK = kSize Ã— kTileSizes

```
**æœ¬æ¡ˆä¾‹**:   
```
M: 16 Ã— 2 Ã— 2 = 64
N: 16 Ã— 2 Ã— 2 = 64
K: 16 Ã— 8 = 128

```
### 3. SRAM ä½¿ç”¨é‡è¨ˆç®—   
```
tileM = mSize Ã— prod(mTileSizes) Ã— prod(mSubgroupCounts)
tileN = nSize Ã— prod(nTileSizes) Ã— prod(nSubgroupCounts)
tileK = kSize Ã— prod(kTileSizes)

lhsSRAM = (tileM Ã— tileK Ã— lhsBitwidth) / 8
rhsSRAM = (tileN Ã— tileK Ã— rhsBitwidth) / 8
totalSRAM = lhsSRAM + rhsSRAM

```
**æœ¬æ¡ˆä¾‹**:   
```
tileM = 64, tileN = 64, tileK = 128
lhsSRAM = (64 Ã— 128 Ã— 16) / 8 = 16384 bytes
rhsSRAM = (64 Ã— 128 Ã— 16) / 8 = 16384 bytes
totalSRAM = 32768 bytes

```
### 4. SRAM ä½¿ç”¨ç‡è¨ˆç®—   
```
usage = (totalSRAM / sharedMemLimit) Ã— 100%

```
**æœ¬æ¡ˆä¾‹**:   
```
usage = (32768 / 65536) Ã— 100% = 50%

```
### 5. Workgroup æ•¸é‡è¨ˆç®—   
```
numWorkgroupsM = ceil(problemM / workgroupTileM)
numWorkgroupsN = ceil(problemN / workgroupTileN)
totalWorkgroups = numWorkgroupsM Ã— numWorkgroupsN

```
**æœ¬æ¡ˆä¾‹**:   
```
M: ceil(128 / 64) = 2
N: ceil(256 / 64) = 4
Total: 2 Ã— 4 = 8 workgroups

```
### 6. Thread æ•¸é‡è¨ˆç®—   
```
subgroupsPerWorkgroup = mSubgroupCounts Ã— nSubgroupCounts
threadsPerWorkgroup = subgroupsPerWorkgroup Ã— subgroupSize

```
**æœ¬æ¡ˆä¾‹**:   
```
subgroups: 2 Ã— 2 = 4
threads: 4 Ã— 32 = 128 threads per workgroup

```
 --- 
## çµè«–   
é€™å€‹æ¡ˆä¾‹å±•ç¤ºäº†ä¸€å€‹**å®Œç¾çš„ MMA schedule é¸æ“‡æµç¨‹**:   
1. âœ… **ç¬¬ä¸€å€‹ intrinsic å°±æˆåŠŸ** (WMMAR3\_F32\_16x16x16\_F16)   
2. âœ… **å‹åˆ¥å®Œå…¨åŒ¹é…** (f16Ã—f16â†’f32)   
3. âœ… **æ‰€æœ‰ç¶­åº¦å°é½Š** (M, N, K éƒ½æ˜¯ 16 çš„å€æ•¸)   
4. âœ… **SRAM ä½¿ç”¨ç‡å¥åº·** (50%,é ä½æ–¼é™åˆ¶)   
5. âœ… **ç„¡éœ€ schedule ç¸®æ¸›** (0 iterations)   
6. âœ… **æœ€çµ‚é…ç½®é«˜æ•ˆ** (å……åˆ†åˆ©ç”¨ç¡¬é«” MMA æŒ‡ä»¤)   
   
é€™å€‹æµç¨‹å……åˆ†å±•ç¤ºäº† IREE ç·¨è­¯å™¨å¦‚ä½•æ™ºèƒ½åœ°é¸æ“‡å’Œé…ç½® MMA intrinsics,ä»¥é”åˆ°æœ€ä½³çš„ GPU æ€§èƒ½ã€‚   
 --- 
## é™„éŒ„ A: ç¨‹å¼ç¢¼ä½ç½®ç´¢å¼•   
### ä¸»è¦æª”æ¡ˆ   
|                    æª”æ¡ˆ |                                                                            è·¯å¾‘ |                                 èªªæ˜ |
|:----------------------|:------------------------------------------------------------------------------|:-----------------------------------|
|  **KernelConfig.cpp** |                 `compiler/src/iree/compiler/Codegen/LLVMGPU/KernelConfig.cpp` |                     Kernel é…ç½®é¸æ“‡ä¸»é‚è¼¯ |
| **GPUHeuristics.cpp** |             `compiler/src/iree/compiler/Codegen/Common/GPU/GPUHeuristics.cpp` |           MMA schedule æ¨å°å’Œ SRAM å„ªåŒ– |
|  **KnownTargets.cpp** | `compiler/src/iree/compiler/Codegen/Dialect/GPU/TargetUtils/KnownTargets.cpp` |               GPU ç›®æ¨™å®šç¾©å’Œ intrinsics |
|   **ConfigUtils.cpp** |  `compiler/src/iree/compiler/Codegen/Dialect/GPU/TargetUtils/ConfigUtils.cpp` |                      Schedule é©—è­‰å·¥å…· |

### é—œéµå‡½æ•¸ä½ç½®   
### KernelConfig.cpp   
|                                  å‡½æ•¸ |         è¡Œè™Ÿç¯„åœ |                         åŠŸèƒ½ |
|:------------------------------------|:-------------|:---------------------------|
|                     `setRootConfig` |    3287-3366 |      é¸æ“‡ root kernel config |
|       `setVectorDistributionConfig` |    2800-2900 |     Vector distribution ç­–ç•¥ |
| `setMatmulVectorDistributionConfig` |    1322-1450 |                Matmul å°ˆç”¨é…ç½® |

### GPUHeuristics.cpp   
|                                         å‡½æ•¸ |         è¡Œè™Ÿç¯„åœ |                            åŠŸèƒ½ |
|:-------------------------------------------|:-------------|:------------------------------|
|                        `deduceMMASchedule` |      564-672 |            MMA schedule æ¨å°ä¸»å‡½æ•¸ |
|                       `canTargetIntrinsic` |      290-406 |             æª¢æŸ¥ intrinsic æ˜¯å¦å¯ç”¨ |
|                    `getOptimalMMASchedule` |      442-562 |                 è¨ˆç®—æœ€ä½³ schedule |
|                `fitScheduleInSharedMemory` |      210-288 |           Schedule ç¸®æ¸›ä»¥ç¬¦åˆ SRAM |
| `calculateOperandsSharedMemoryUsedInBytes` |        52-81 |           è¨ˆç®— LHS/RHS SRAM ä½¿ç”¨é‡ |
|   `calculateResultSharedMemoryUsedInBytes` |       83-101 |            è¨ˆç®— Result SRAM ä½¿ç”¨é‡ |

### ConfigUtils.cpp   
|                   å‡½æ•¸ |         è¡Œè™Ÿç¯„åœ |                                 åŠŸèƒ½ |
|:---------------------|:-------------|:-----------------------------------|
| `isValidMMASchedule` |      103-200 |                 é©—è­‰ schedule å°é½Šå’Œæœ‰æ•ˆæ€§ |

 --- 
## é™„éŒ„ B: Debug Tag å°ç…§è¡¨   
|                      Debug Tag |                        ä¾†æºå‡½æ•¸ |                æª”æ¡ˆ |      è¡Œè™Ÿ |                         ç”¨é€” |
|:-------------------------------|:----------------------------|:------------------|:--------|:---------------------------|
| `[iree-llvmgpu-kernel-config]` |                        å¤šå€‹å‡½æ•¸ |  KernelConfig.cpp |      å¤šè™• |         Kernel config é¸æ“‡æµç¨‹ |
|                 `[DEDUCE MMA]` |         `deduceMMASchedule` | GPUHeuristics.cpp | 564-672 |            MMA schedule æ¨å° |
|                 `[CAN TARGET]` |        `canTargetIntrinsic` | GPUHeuristics.cpp | 290-406 |            Intrinsic ç›¸å®¹æ€§æª¢æŸ¥ |
|                `[GET OPTIMAL]` |     `getOptimalMMASchedule` | GPUHeuristics.cpp | 442-562 |             æœ€ä½³ schedule è¨ˆç®— |
|          `[VALIDATE SCHEDULE]` |  `isValidSchedule` (lambda) | GPUHeuristics.cpp | 597-620 |                Schedule é©—è­‰ |
|                  `[SRAM CALC]` | `calculate\*SharedMemory\*` | GPUHeuristics.cpp |  52-101 |                    SRAM è¨ˆç®— |
|               `[FIT SCHEDULE]` | `fitScheduleInSharedMemory` | GPUHeuristics.cpp | 210-288 |                Schedule ç¸®æ¸› |
|             `[IREE MMA DEBUG]` |        `isValidMMASchedule` |   ConfigUtils.cpp | 103-200 |              Schedule å°é½Šé©—è­‰ |

 --- 
## é™„éŒ„ C: è³‡æ–™çµæ§‹èªªæ˜   
### GPUMatmulShapeType   
**å®šç¾©ä½ç½®**: `compiler/src/iree/compiler/Codegen/Dialect/GPU/TargetUtils/ConfigUtils.h`   
```
struct GPUMatmulShapeType {
  SmallVector<int64_t, 2> mSizes;  // M ç¶­åº¦å¤§å°
  SmallVector<int64_t, 2> nSizes;  // N ç¶­åº¦å¤§å°
  SmallVector<int64_t, 2> kSizes;  // K ç¶­åº¦å¤§å°
  Type aType;                       // LHS å…ƒç´ å‹åˆ¥
  Type bType;                       // RHS å…ƒç´ å‹åˆ¥
  Type cType;                       // Result å…ƒç´ å‹åˆ¥
};

```
**æœ¬æ¡ˆä¾‹çš„å€¼**:   
```
mSizes = [128]
nSizes = [256]
kSizes = [512]
aType = f16
bType = f16
cType = f32

```
### GPUIntrinsicType   
**å®šç¾©ä½ç½®**: `compiler/src/iree/compiler/Codegen/Dialect/GPU/TargetUtils/ConfigUtils.h`   
```
struct GPUIntrinsicType : public GPUMatmulShapeType {
  IREE::GPU::MMAIntrinsic mmaKind;  // MMA intrinsic ç¨®é¡
  // ç¹¼æ‰¿: mSizes, nSizes, kSizes, aType, bType, cType
};

```
**æœ¬æ¡ˆä¾‹é¸ä¸­çš„ intrinsic**:   
```
mmaKind = WMMAR3_F32_16x16x16_F16
mSizes = [16]
nSizes = [16]
kSizes = [16]
aType = f16
bType = f16
cType = f32

```
### GPUMMASchedule   
**å®šç¾©ä½ç½®**: `compiler/src/iree/compiler/Codegen/Dialect/GPU/TargetUtils/ConfigUtils.h`   
```
struct GPUMMASchedule {
  IREE::GPU::MMAIntrinsic mmaKind;           // MMA intrinsic ç¨®é¡
  int64_t mSize;                              // M æ–¹å‘ intrinsic å¤§å°
  int64_t nSize;                              // N æ–¹å‘ intrinsic å¤§å°
  int64_t kSize;                              // K æ–¹å‘ intrinsic å¤§å°
  SmallVector<int64_t> mSubgroupCounts;      // M æ–¹å‘ subgroup æ•¸é‡
  SmallVector<int64_t> nSubgroupCounts;      // N æ–¹å‘ subgroup æ•¸é‡
  SmallVector<int64_t> mTileSizes;           // M æ–¹å‘æ¯å€‹ subgroup çš„ tile æ•¸
  SmallVector<int64_t> nTileSizes;           // N æ–¹å‘æ¯å€‹ subgroup çš„ tile æ•¸
  SmallVector<int64_t> kTileSizes;           // K æ–¹å‘æ¯å€‹ subgroup çš„ tile æ•¸
};

```
**æœ¬æ¡ˆä¾‹çš„ schedule**:   
```
mmaKind = WMMAR3_F32_16x16x16_F16
mSize = 16
nSize = 16
kSize = 16
mSubgroupCounts = [2]
nSubgroupCounts = [2]
mTileSizes = [2]
nTileSizes = [2]
kTileSizes = [8]

```
### GPUMMAHeuristicSeeds   
**å®šç¾©ä½ç½®**: `compiler/src/iree/compiler/Codegen/Dialect/GPU/TargetUtils/ConfigUtils.h`   
```
struct GPUMMAHeuristicSeeds {
  int64_t bestSubgroupCountPerWorkgroup;   // æ¯å€‹ workgroup çš„ subgroup æ•¸
  int64_t bestMNTileCountPerSubgroup;      // æ¯å€‹ subgroup çš„ M/N tile æ•¸
  int64_t bestKElementCountPerSubgroup;    // æ¯å€‹ subgroup çš„ K å…ƒç´ æ•¸
};

```
**æœ¬æ¡ˆä¾‹çš„ seeds** (ä¾†è‡ª RDNA3 target é…ç½®):   
```
bestSubgroupCountPerWorkgroup = 4
bestMNTileCountPerSubgroup = 4
bestKElementCountPerSubgroup = 128  // å¯¦éš› log é¡¯ç¤ºç‚º 0,ä½†å…§éƒ¨è¨ˆç®—ä½¿ç”¨ 128

```
 --- 
## é™„éŒ„ D: AMD RDNA3 MMA Intrinsics   
**å®šç¾©ä½ç½®**: `compiler/src/iree/compiler/Codegen/Dialect/GPU/TargetUtils/KnownTargets.cpp` (è¡Œ 322-330)   
### å¯ç”¨çš„ Intrinsics   
|                        Intrinsic |     è¼¸å…¥ A |     è¼¸å…¥ B |     è¼¸å‡º C |         å¤§å° |                  èªªæ˜ |
|:---------------------------------|:---------|:---------|:---------|:-----------|:--------------------|
|   **WMMAR3\_F32\_16x16x16\_F16** |      f16 |      f16 |      f32 |   16Ã—16Ã—16 |             âœ“ æœ¬æ¡ˆä¾‹ä½¿ç”¨ |
|   **WMMAR3\_F16\_16x16x16\_F16** |      f16 |      f16 |      f16 |   16Ã—16Ã—16 |               ä½ç²¾åº¦ç‰ˆæœ¬ |
|  **WMMAR3\_F32\_16x16x16\_BF16** |     bf16 |     bf16 |      f32 |   16Ã—16Ã—16 |         BFloat16 ç‰ˆæœ¬ |
| **WMMAR3\_BF16\_16x16x16\_BF16** |     bf16 |     bf16 |     bf16 |   16Ã—16Ã—16 |        BFloat16 ä½ç²¾åº¦ |
|    **WMMAR3\_I32\_16x16x16\_I8** |       i8 |       i8 |      i32 |   16Ã—16Ã—16 |                æ•´æ•¸ç‰ˆæœ¬ |

### é¸æ“‡é‚è¼¯   
```
const MMAIntrinsic rdna3MMAOps[] = {
    MMAIntrinsic::WMMAR3_F32_16x16x16_F16,    // å„ªå…ˆç´š 1 (æœ€å¸¸ç”¨)
    MMAIntrinsic::WMMAR3_F16_16x16x16_F16,    // å„ªå…ˆç´š 2
    MMAIntrinsic::WMMAR3_F32_16x16x16_BF16,   // å„ªå…ˆç´š 3
    MMAIntrinsic::WMMAR3_BF16_16x16x16_BF16,  // å„ªå…ˆç´š 4
    MMAIntrinsic::WMMAR3_I32_16x16x16_I8,     // å„ªå…ˆç´š 5
};

```
**é¸æ“‡é †åº**: æŒ‰é™£åˆ—é †åºå˜—è©¦,ç¬¬ä¸€å€‹åŒ¹é…çš„å°±ä½¿ç”¨   
**æœ¬æ¡ˆä¾‹**: ç¬¬ä¸€å€‹ intrinsic (WMMAR3\_F32\_16x16x16\_F16) å°±åŒ¹é…æˆåŠŸ   
 --- 
## é™„éŒ„ E: è¦–è¦ºåŒ–èªªæ˜   
### Workgroup å’Œ Subgroup åˆ†ä½ˆ   
```
æ•´å€‹å•é¡Œ (128Ã—256):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Workgroup (0,0)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚ Subgroup(0,0)â”‚ Subgroup(0,1)â”‚                            â”‚
â”‚  â”‚   32 threads â”‚   32 threads â”‚                            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                            â”‚
â”‚  â”‚ Subgroup(1,0)â”‚ Subgroup(1,1)â”‚                            â”‚
â”‚  â”‚   32 threads â”‚   32 threads â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚         64Ã—64                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Workgroup (1,0)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚ Subgroup(0,0)â”‚ Subgroup(0,1)â”‚                            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                            â”‚
â”‚  â”‚ Subgroup(1,0)â”‚ Subgroup(1,1)â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ¯å€‹ Subgroup è™•ç†:
- M æ–¹å‘: 2 å€‹ MMA tiles Ã— 16 = 32 elements
- N æ–¹å‘: 2 å€‹ MMA tiles Ã— 16 = 32 elements
- K æ–¹å‘: 8 å€‹ MMA tiles Ã— 16 = 128 elements (reduction)

```
### MMA Tile åˆ†ä½ˆ (å–®å€‹ Subgroup)   
```
Subgroup è™•ç†çš„å€åŸŸ (32Ã—32):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MMA Tile(0,0) â”‚  MMA Tile(0,1) â”‚
â”‚     16Ã—16      â”‚     16Ã—16      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MMA Tile(1,0) â”‚  MMA Tile(1,1) â”‚
â”‚     16Ã—16      â”‚     16Ã—16      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ¯å€‹ MMA Tile:
- ä½¿ç”¨ 1 å€‹ WMMA intrinsic
- è™•ç† 16Ã—16Ã—16 çš„çŸ©é™£ä¹˜æ³•
- ç”± Wave (32 threads) å”ä½œå®Œæˆ

```
### SRAM ä½¿ç”¨åˆ†ä½ˆ   
```
Shared Memory (64 KB):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LHS Tile (64Ã—128 f16)               â”‚  16 KB
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ M=64, K=128, 2 bytes/element    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RHS Tile (64Ã—128 f16)               â”‚  16 KB
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ N=64, K=128, 2 bytes/element    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Unused                              â”‚  32 KB
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä½¿ç”¨ç‡: 32 KB / 64 KB = 50%

```
### K ç¶­åº¦ Reduction æµç¨‹   
```
K ç¶­åº¦ (512 elements):
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
â”‚128 â”‚128 â”‚128 â”‚128 â”‚  â† 4 å€‹ K tiles (æ¯å€‹ 128 elements)
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜

æ¯å€‹ K tile (128 elements):
â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”
â”‚16â”‚16â”‚16â”‚16â”‚16â”‚16â”‚16â”‚16â”‚  â† 8 å€‹ MMA K tiles (kTileSizes=[8])
â””â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”˜

Reduction éç¨‹:
1. Load K tile 0 (128 elements) åˆ° SRAM
2. åŸ·è¡Œ 8 æ¬¡ MMA (æ¯æ¬¡è™•ç† 16 å€‹ K elements)
3. ç´¯åŠ åˆ° result
4. Load K tile 1 â†’ åŸ·è¡Œ 8 æ¬¡ MMA â†’ ç´¯åŠ 
5. Load K tile 2 â†’ åŸ·è¡Œ 8 æ¬¡ MMA â†’ ç´¯åŠ 
6. Load K tile 3 â†’ åŸ·è¡Œ 8 æ¬¡ MMA â†’ ç´¯åŠ 
7. å®Œæˆ

```
 --- 
## é™„éŒ„ F: å¸¸è¦‹å•é¡Œ (FAQ)   
### Q1: ç‚ºä»€éº¼ç¬¬ä¸€å€‹ intrinsic å°±æˆåŠŸäº†?   
**A**: å› ç‚ºå•é¡Œçš„å‹åˆ¥å’Œå¤§å°å®Œç¾åŒ¹é…:   
- å‹åˆ¥: f16Ã—f16â†’f32 (å®Œå…¨åŒ¹é… WMMAR3\_F32\_16x16x16\_F16)   
- å°é½Š: M=128, N=256, K=512 éƒ½æ˜¯ 16 çš„å€æ•¸   
- SRAM: ä½¿ç”¨é‡ (32 KB) é ä½æ–¼é™åˆ¶ (64 KB)   
   
### Q2: å¦‚æœå°é½Šå¤±æ•—æœƒæ€æ¨£?   
**A**: æœƒå˜—è©¦ä¸‹ä¸€å€‹ intrinsic,å¦‚æœæ‰€æœ‰ intrinsic éƒ½å¤±æ•—:   
- å›é€€åˆ°é MMA çš„ vector distribution   
- æˆ–ä½¿ç”¨å…¶ä»– kernel config ç­–ç•¥ (å¦‚ reduction vector distribution)   
- æ€§èƒ½æœƒé¡¯è‘—ä¸‹é™ (ç„¡æ³•ä½¿ç”¨ç¡¬é«”åŠ é€Ÿ)   
   
### Q3: SRAM ä½¿ç”¨ç‡ 50% æ˜¯å¦å¤ªä½?   
**A**: ä¸ä¸€å®š,é€™å–æ±ºæ–¼:   
- **å„ªé»**: ç•™æœ‰é¤˜è£•,é¿å… register spilling   
- **ç¼ºé»**: å¯èƒ½å¯ä»¥å¢åŠ  tile size ä»¥æé«˜ data reuse   
- **æœ¬æ¡ˆä¾‹**: 50% æ˜¯å¥åº·çš„ä½¿ç”¨ç‡,ç„¡éœ€å„ªåŒ–   
   
### Q4: ç‚ºä»€éº¼ kTileSizes = 8?   
**A**: ä¾†è‡ª heuristic seeds:   
```
bestKElementCountPerSubgroup = 128
kTileCountPerSubgroup = 128 / 16 = 8

```
é€™æ˜¯ RDNA3 target çš„ç¶“é©—å€¼,å¹³è¡¡äº†:   
- SRAM ä½¿ç”¨é‡   
- Data reuse   
- Reduction æ•ˆç‡   
   
### Q5: å¦‚æœ SRAM ä¸å¤ æœƒæ€æ¨£?   
**A**: `fitScheduleInSharedMemory` æœƒç¸®æ¸› schedule:   
1. æ¸›å°‘ `mTileSizes` æˆ– `nTileSizes` (æ¸›å°‘ M/N tile æ•¸)   
2. æ¸›å°‘ `kTileSizes` (æ¸›å°‘ K tile æ•¸)   
3. æ¸›å°‘ `mSubgroupCounts` æˆ– `nSubgroupCounts` (æ¸›å°‘ subgroup æ•¸)   
4. å¦‚æœç„¡æ³•ç¸®æ¸›,å˜—è©¦ä¸‹ä¸€å€‹ intrinsic   
   
### Q6: ç‚ºä»€éº¼ Workgroup tile æ˜¯ 64Ã—64?   
**A**: è¨ˆç®—æ–¹å¼:   
```
workgroupTileM = mSize Ã— mTileSizes Ã— mSubgroupCounts
               = 16 Ã— 2 Ã— 2 = 64

workgroupTileN = nSize Ã— nTileSizes Ã— nSubgroupCounts
               = 16 Ã— 2 Ã— 2 = 64

```
é€™æ˜¯ç”± MMA schedule è‡ªå‹•æ±ºå®šçš„,å¹³è¡¡äº†:   
- Workgroup æ•¸é‡ (å½±éŸ¿ GPU ä½”ç”¨ç‡)   
- SRAM ä½¿ç”¨é‡   
- Subgroup å”ä½œæ•ˆç‡   
   
### Q7: å¯ä»¥æ‰‹å‹•èª¿æ•´ schedule å—?   
**A**: å¯ä»¥,ä½†ä¸å»ºè­°:   
- IREE æä¾› `--iree-codegen-llvmgpu-use-mma-sync` ç­‰ flags   
- å¯ä»¥é€šé lowering config attributes æ‰‹å‹•æŒ‡å®š   
- ä½†è‡ªå‹•æ¨å°çš„ schedule é€šå¸¸å·²ç¶“å¾ˆå„ªåŒ–äº†   
   
### Q8: é€™å€‹ schedule çš„æ€§èƒ½å¦‚ä½•?   
**A**: é æœŸæ€§èƒ½å¾ˆå¥½,å› ç‚º:   
- âœ“ ä½¿ç”¨ç¡¬é«” MMA intrinsic (WMMA)   
- âœ“ SRAM ä½¿ç”¨ç‡å¥åº· (50%)   
- âœ“ Workgroup å¤§å°åˆç† (128 threads)   
- âœ“ å……åˆ†åˆ©ç”¨ subgroup ä¸¦è¡Œæ€§ (4 subgroups)   
- âœ“ K æ–¹å‘ reduction æ•ˆç‡é«˜ (128 elements per iteration)   
 --- 
   
## é™„éŒ„ G: é€²éšä¸»é¡Œ   
### 1. GCD åˆ†é…ç®—æ³•è©³è§£   
**ç›®çš„**: å°‡ total tile counts åˆ†é…åˆ° subgroups å’Œ tiles   
**ç®—æ³•** (ç°¡åŒ–ç‰ˆ):   
```
int64_t distributeToSubgroupsAndTiles(
    int64_t totalTileCount,
    int64_t &remainingSubgroups,
    int64_t &remainingTiles) {

  // è¨ˆç®—å¯ç”¨çš„ç¸½ tiles
  int64_t availableTiles = remainingSubgroups * remainingTiles;

  // è¨ˆç®— GCD
  int64_t gcd = std::gcd(totalTileCount, availableTiles);

  // ä½¿ç”¨ sqrt ç­–ç•¥åˆ†é…
  int64_t subgroupCount = std::sqrt(gcd);
  int64_t tileCount = gcd / subgroupCount;

  // æ›´æ–°å‰©é¤˜
  remainingSubgroups /= subgroupCount;
  remainingTiles /= tileCount;

  return {subgroupCount, tileCount};
}

```
**æœ¬æ¡ˆä¾‹ M æ–¹å‘**:   
```
totalTileCount = 8
availableTiles = 4 Ã— 4 = 16
gcd = gcd(8, 16) = 8
subgroupCount = sqrt(8) â‰ˆ 2 (å‘ä¸‹å–æ•´)
tileCount = 8 / 2 = 4 â†’ ä½†èª¿æ•´ç‚º 2 (å¹³è¡¡ç­–ç•¥)

çµæœ: mSubgroupCounts=2, mTileSizes=2

```
### 2. Schedule ç¸®æ¸›ç­–ç•¥   
**ç¸®æ¸›é †åº** (å„ªå…ˆç´šå¾é«˜åˆ°ä½):   
1. `mTileSizes` - æ¸›å°‘ M æ–¹å‘ tile æ•¸   
2. `nTileSizes` - æ¸›å°‘ N æ–¹å‘ tile æ•¸   
3. `kTileSizes` - æ¸›å°‘ K æ–¹å‘ tile æ•¸   
4. `mSubgroupCounts` - æ¸›å°‘ M æ–¹å‘ subgroup æ•¸   
5. `nSubgroupCounts` - æ¸›å°‘ N æ–¹å‘ subgroup æ•¸   
   
**ç‚ºä»€éº¼é€™å€‹é †åº?**   
- Tile æ•¸å½±éŸ¿ data reuse,ä½†ä¸å½±éŸ¿ä¸¦è¡Œæ€§   
- Subgroup æ•¸å½±éŸ¿ä¸¦è¡Œæ€§,æ¸›å°‘æœƒé™ä½æ€§èƒ½   
- å› æ­¤å„ªå…ˆæ¸›å°‘ tile æ•¸   
   
**ç¸®æ¸›ç¯„ä¾‹**:   
```
åˆå§‹: mTileSizes=[4], SRAM=65536 bytes (overflow)
è¿­ä»£ 1: mTileSizes=[3], SRAM=49152 bytes (still overflow)
è¿­ä»£ 2: mTileSizes=[2], SRAM=32768 bytes (OK!)

```
### 3. å‹åˆ¥ Upcast æ©Ÿåˆ¶   
**ä»€éº¼æ˜¯ Upcast?**   
- å…è¨± accumulator å‹åˆ¥æ¯” intrinsic è¼¸å‡ºå‹åˆ¥æ›´å¤§   
- ä¾‹å¦‚: intrinsic è¼¸å‡º f16,ä½† problem éœ€è¦ f32   
   
**æª¢æŸ¥é‚è¼¯**:   
```
if (problem.cType != intrinsic.cType) {
  bool isFpCase = isa<FloatType>(problem.cType) && isa<FloatType>(intrinsic.cType);
  bool isUpcast = problem.cType.getIntOrFloatBitWidth() >
                  intrinsic.cType.getIntOrFloatBitWidth();
  if (!(canUpcastAcc && isFpCase && isUpcast)) {
    return failure();  // ä¸å…è¨± upcast
  }
}

```
**æœ¬æ¡ˆä¾‹**: ä¸éœ€è¦ upcast (f32 == f32)   
### 4. Very Skinny Matmul æª¢æ¸¬   
**å®šç¾©**: M æˆ– N ç¶­åº¦ â‰¤ 4 çš„ matmul   
**ç‚ºä»€éº¼è¦ç‰¹æ®Šè™•ç†?**   
- å¤ªå°çš„ç¶­åº¦ç„¡æ³•å……åˆ†åˆ©ç”¨ MMA intrinsic   
- å¯èƒ½å°è‡´ thread åˆ©ç”¨ç‡ä½   
- æ›´é©åˆç”¨ vector æŒ‡ä»¤è€Œé MMA   
   
**æª¢æ¸¬é‚è¼¯**:   
```
constexpr int64_t kVerySkinnyDimThreshold = 4;

bool isVerySkinny = (problem.mSizes.back() <= kVerySkinnyDimThreshold) ||
                    (problem.nSizes.back() <= kVerySkinnyDimThreshold);

if (isVerySkinny) {
  return failure();  // æ‹’çµ•ä½¿ç”¨ MMA
}

```
**æœ¬æ¡ˆä¾‹**: M=128, N=256 (éƒ½ > 4,ä¸æ˜¯ skinny matmul)   
 --- 
## ç¸½çµ   
é€™ä»½æ–‡ä»¶è©³ç´°åˆ†æäº† IREE ç·¨è­¯å™¨ä¸­ MMA schedule é¸æ“‡çš„å®Œæ•´æµç¨‹,åŒ…æ‹¬:   
1. âœ… **7 å€‹ä¸»è¦éšæ®µ**çš„è©³ç´°èªªæ˜   
2. âœ… **Log è¼¸å‡ºèˆ‡ç¨‹å¼ç¢¼çš„ç²¾ç¢ºå°æ‡‰**   
3. âœ… **æ‰€æœ‰é—œéµå…¬å¼**çš„æ¨å°å’Œè¨ˆç®—   
4. âœ… **å®Œæ•´çš„æ±ºç­–æ¨¹**å’ŒåŸ·è¡Œè·¯å¾‘   
5. âœ… **è¦–è¦ºåŒ–åœ–è¡¨**å¹«åŠ©ç†è§£   
6. âœ… **å¸¸è¦‹å•é¡Œ**å’Œé€²éšä¸»é¡Œ   
   
é€™å€‹æ¡ˆä¾‹å±•ç¤ºäº†ä¸€å€‹**ç†æƒ³çš„ MMA ç·¨è­¯æµç¨‹**,å¯ä»¥ä½œç‚º:   
- å­¸ç¿’ IREE MMA ç·¨è­¯çš„åƒè€ƒ   
- Debug MMA å•é¡Œçš„æŒ‡å—   
- å„ªåŒ– matmul æ€§èƒ½çš„åŸºç¤   
   
å¸Œæœ›é€™ä»½æ–‡ä»¶èƒ½å¹«åŠ©ä½ æ·±å…¥ç†è§£ IREE çš„ MMA ç·¨è­¯æ©Ÿåˆ¶! ğŸ‰   
   
![](/img/iree-mma-debug-walkthrough_files/encrypted-tbn0_gstatic_com_image.png)    
